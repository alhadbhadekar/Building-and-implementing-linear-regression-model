# -*- coding: utf-8 -*-
"""Building and implementing Linear Regression from scratch.ipynb

Automatically generated by Colab.

Linear Regression:

Y = wX + b

Y --> Dependent Variable

X --> Independent Variable

w --> weight

b --> bias

Gradient Descent:

Gradient Descent is an optimization algorithm used for minimizing the loss function in various machine learning algorithms. It is used for updating the parameters of the learning model.

w = w - α*dw

b = b - α*db

Learning Rate:

Learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function.
"""

# importing numpy library
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

"""Linear Regression"""

class Linear_Regression():

  # initiating the parameters (learning rate & no. of iterations)
  def __init__(self, learning_rate, no_of_iterations):

    self.learning_rate = learning_rate
    self.no_of_iterations = no_of_iterations

  def fit(self, X, Y):
    # number of training examples & number of features
    self.m, self.n = X.shape # number of rows & columns

    # initiating the weight & bias
    self.w = np.zeros(self.n)
    self.b = 0
    self.X = X
    self.Y = Y

    # implementing Gradient Descent

    for i in range(self.no_of_iterations):
      self.update_weights()

  def update_weights(self):
    Y_prediction = self.predict(self.X)

    # calculating gradients
    dw = - (2 * np.sum((self.X.T).dot(self.Y - Y_prediction))) / self.m

    db = - 2 * np.sum(self.Y - Y_prediction)/self.m

    # updating the weights

    self.w = self.w - self.learning_rate*dw
    self.b = self.b - self.learning_rate*db

  def predict(self, X):
    return X.dot(self.w) + self.b

"""Using Linear Regression model for prediction

Data Processing
"""

# loading the data from csv file to pandas dataframe
salary_data = pd.read_csv('/content/salary_data.csv')

# printing the first 5 rows of the dataframe
salary_data.head()

# number of rows & columns in the dataset
salary_data.shape

# checking for missing values
salary_data.isnull().sum()

"""Splitting the feature & target"""

X = salary_data.iloc[:,:-1].values
Y = salary_data.iloc[:,1].values

print(X)

print(Y)

"""Splitting the data to training data & Test data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33,random_state = 2 )

"""Train the Logistic Regression Model"""

model = Linear_Regression(learning_rate = 0.01, no_of_iterations = 1000)

model.fit(X_train, Y_train)

# print the parameters

print('weight = ', model.w)
print('bias = ', model.b)

"""Predict the salary value for test data"""

test_data_prediction = model.predict(X_test)

print(test_data_prediction)

"""Visualizing the predicted values and actual values"""

plt.scatter( X_test, Y_test, color = 'red' )
plt.plot( X_test, test_data_prediction, color = 'blue' )
plt.xlabel( 'Work Experience' )
plt.ylabel( 'Salary' )
plt.title( 'Salary vs Experience' )
plt.show()

